{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9e3a04",
   "metadata": {},
   "source": [
    "# Black-box optimization exercise\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This is part of the capstone project for the Professional Certificate in Machine Learning and AI from Imperial College Business School.\n",
    "\n",
    "The goal is the optimization of 8 black-box functions. For each of the functions 10 initial data points are given and each week I must submit a new data point to evaluate. This simulates a costly process of actual evaluation.\n",
    "\n",
    "All variables range from 0 to 1.\n",
    "\n",
    "This notebook will document the whole process. It is structured in a way that follows, function by function and week by week, the thought process and techniques used.\n",
    "\n",
    "This kind of problem is the textbook example of usage of Bayesian optimization. \n",
    "\n",
    "In this kind of problem the most widely used surrogate function is a Gaussian process because, among other things, it already comes with uncertainty measures embedded. I will be testing our different kernels and acquisition functions depending on the case at hand. The litterature suggests applying. Automatic relevance determination (ARD) to the kernels which allows for differnet \"length scale\" for each dimension. (https://www.pnas.org/doi/10.1073/pnas.1912342117)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2846be0f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The challenge provided a certain number of initial points for all 8 functions and then, after each submission, files containing the results a provided.\n",
    "\n",
    "In this notebook, a dataframe called results_df contains all such results, however they are loaded progressively week by week into variables called fx_inputs and fx_outputs, so as to guarantee that progressive data acquisition can be reproduced throught this notebook. It is therefore very important that all cells are executed in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc868c",
   "metadata": {},
   "source": [
    "### Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment preparation, all libs imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install pydot\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel as C, Matern\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import qmc\n",
    "from scipy.stats import norm\n",
    "from skopt import forest_minimize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.stats as stats\n",
    "import ast, re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment preparation, populating `results_df`, which is a dataframe with all the results known for all functions\n",
    "\n",
    "results_df = pd.DataFrame(columns=['week', 'function', 'known_best', 'provided_input', 'output', 'submission_improved'])\n",
    "\n",
    "# Load initial values\n",
    "for X in range(1, 9):\n",
    "    inputs_path = f\"initial_data/function_{X}/initial_inputs.npy\"\n",
    "    outputs_path = f\"initial_data/function_{X}/initial_outputs.npy\"\n",
    "    \n",
    "    globals()[f\"f{X}_inputs\"] = np.load(inputs_path)\n",
    "    globals()[f\"f{X}_outputs\"] = np.load(outputs_path)\n",
    "\n",
    "    results_df.loc[len(results_df)] = [0, X, np.max(globals()[f\"f{X}_outputs\"]), globals()[f\"f{X}_inputs\"][np.argmax(globals()[f\"f{X}_outputs\"])], np.nan, False]\n",
    "\n",
    "# Load results dataframe with each weeks inputs and outputs\n",
    "#for X in range(1,3):\n",
    "inputs_path = f\"submissions/w5_inputs.txt\"\n",
    "outputs_path = f\"submissions/w5_outputs.txt\"\n",
    "\n",
    "#Inputs\n",
    "with open(inputs_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split out the separate sets\n",
    "raw_sets = re.split(r'\\]\\s*\\[', content.strip())\n",
    "raw_sets = [s.strip('[]') for s in raw_sets]\n",
    "\n",
    "# Parse each set into lists of numpy arrays\n",
    "all_sets = []\n",
    "for s in raw_sets:\n",
    "    arrays_raw = re.findall(r'array\\((.*?)\\)', s, re.DOTALL)\n",
    "    instance_set = [np.array(eval(a)) for a in arrays_raw]\n",
    "    all_sets.append(instance_set)\n",
    "\n",
    "# Transpose structure: arrays[i] has i-th array of each set\n",
    "max_len = max(len(s) for s in all_sets)\n",
    "arrays = []\n",
    "for i in range(max_len):\n",
    "    group = []\n",
    "    for n, s in enumerate(all_sets, start=1):\n",
    "        if i < len(s):\n",
    "            #week number, function, best_output, provided_input, output, submission_improved\n",
    "            results_df.loc[len(results_df)] = [n, i+1, np.nan, s[i], np.nan, False]\n",
    "    \n",
    "#Outputs\n",
    "with open(outputs_path, 'r') as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        content = line.strip()\n",
    "\n",
    "        # Replace 'np.float64(' and ')' so the string only has floats, then use ast.literal_eval for safety\n",
    "        content_clean = content.replace('np.float64(', '').replace(')', '')\n",
    "        float_list = ast.literal_eval(f'[{content_clean}]')\n",
    "\n",
    "        outputs = np.array(float_list, dtype=np.float64)\n",
    "\n",
    "        # for each function\n",
    "        for i in range(0,8):\n",
    "            #Determine if the submission if best than the known best previous week (hence the -1)\n",
    "            row = results_df[(results_df['week'] == line_number-1) & (results_df['function'] == i+1)]\n",
    "            known_best = row['known_best'].values[0]\n",
    "        \n",
    "            improved = (outputs[0,i] > known_best)\n",
    "            if improved:\n",
    "                known_best = outputs[0,i]\n",
    "            # populate the dataframe\n",
    "            condition = (results_df['week'] == line_number) & (results_df['function'] == i+1)\n",
    "            results_df.loc[condition, 'submission_improved'] = improved\n",
    "            results_df.loc[condition, 'known_best'] = known_best\n",
    "            results_df.loc[condition, 'output'] = outputs[0,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment preparation, definition of some common functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0712133",
   "metadata": {},
   "source": [
    "### Observation of weekly results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['function', 'week'])\n",
    "\n",
    "results_df[results_df['week'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['week'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96852a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['week'] == 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8368b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['week'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['week'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bffbe1f",
   "metadata": {},
   "source": [
    "## Function 1\n",
    "\n",
    "This function is a function with a 1D output and a 2D input. \n",
    "\n",
    "This is the description of the function: Detect likely contamination sources in a two-dimensional area, such as a radiation field, where only proximity yields a non-zero reading. The system uses Bayesian optimisation to tune detection parameters and reliably identify both strong and weak sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b17068f",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "This is a 2D function, so we can start by plotting the known datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45cc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f1_inputs[:, 0]\n",
    "x2 = f1_inputs[:, 1]\n",
    "y = f1_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f1: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f1_inputs)}\")\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e5214",
   "metadata": {},
   "source": [
    "Most values are rather on the lower end, which is normal because radiation will be low outside the contaminated area. Peaks are expected to be localized.\n",
    "\n",
    "We can try a Matern kernel in a Gaussian process regressor to consider that data is not smooth, with a smart selection of nu. If nu tends to infinity, then this behaves as a RBF kernel (reference: https://andrewcharlesjones.github.io/journal/matern-kernels.html). We will initially try with a nu of 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Matern(length_scale=[0.1, 0.1], length_scale_bounds=(0.05, 0.5), nu=1.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f1_inputs, f1_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c=f1_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb514c6",
   "metadata": {},
   "source": [
    "I am getting warnings about the optimal values being to close to the bounds provided, so let's try again with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Matern(length_scale=[0.1, 0.1], length_scale_bounds=(1e-2, 1e5), nu=1.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f1_inputs, f1_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c=f1_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a94903",
   "metadata": {},
   "source": [
    "As this is a problem that must encourage exploration, let's use a UCB acquisition function, with a choice of k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdef6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 3.0\n",
    "UCB = Y_mean + kappa * Y_std  # shape = (grid_size, grid_size)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X1, X2, UCB, cmap='plasma', levels=50)\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c='k', s=50, label='Observed points')\n",
    "plt.colorbar(label='UCB acquisition value')\n",
    "plt.title(f\"UCB Acquisition Function (kappa={kappa})\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b54d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_grid[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n",
    "\n",
    "# With the other bounds the suggested submission was 0.78787879 0.7979798"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78190a",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.373737-0.232323"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1600af",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ddf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20e3d7",
   "metadata": {},
   "source": [
    "Let's try the same thing but adjusting the surrogate function so that the importance is given to both parameters. UCB as acquisition function favors exploration, which is what we want at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad471fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = C(1.0, (1e-5, 1e5)) * Matern(length_scale=[0.05, 0.05], length_scale_bounds=(0.01, 0.3), nu=2.5) + WhiteKernel(noise_level=1e-8, noise_level_bounds=(1e-12, 1e2))\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=50,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f1_inputs, f1_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c=f1_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 3.0\n",
    "UCB = Y_mean + kappa * Y_std  # shape = (grid_size, grid_size)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X1, X2, UCB, cmap='plasma', levels=50)\n",
    "plt.scatter(f1_inputs[:,0], f1_inputs[:,1], c='k', s=50, label='Observed points')\n",
    "plt.colorbar(label='UCB acquisition value')\n",
    "plt.title(f\"UCB Acquisition Function (kappa={kappa})\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_grid[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3bc413",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.989899-0.767677"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52b018",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65622597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5bbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f1_inputs[:, 0]\n",
    "x2 = f1_inputs[:, 1]\n",
    "y = f1_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f1: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f1_inputs)}\")\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef02e8",
   "metadata": {},
   "source": [
    "We haven't had any improvement for this function so far. It is known that values only peak close to a contamination source. One has already been identified (blue dot above), the goal is to determine if other exist in the 2D plane.\n",
    "\n",
    "In preparation for more complex cases, I am exploring forest_minimize from skopt which efficiently maximizes the value of the acquisition function. This will help also with high-dimensional cases. I am using a L-BFGS-B (Limited-memory Broyden–Fletcher–Goldfarb–Shanno with Bounds), which according to my limited research is optimal for bounded sets of input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*2, nu=1.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-5, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f1_inputs, f1_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f1_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "num_restarts = 1500 # I have incremented this until the estimation did no longer move (fixed random seed)\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 2)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e84fc",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.405019-0.162145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4d82c",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c46b52",
   "metadata": {},
   "source": [
    "No improvement has been possible so far. The maximum value is part of the initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28318118",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f1_inputs[:, 0]\n",
    "x2 = f1_inputs[:, 1]\n",
    "y = f1_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f1: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f1_inputs)}\")\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*2, nu=1.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-5, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f1_inputs, f1_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f1_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "num_restarts = 150 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 2)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point_ei = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ei):\", next_point_ei)\n",
    "\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "dims = 2\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 50\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    #choosing kappa 2.7 \n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 1.7), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ucb):\", next_point_ucb)\n",
    "\n",
    "\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ucb.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b59f46",
   "metadata": {},
   "source": [
    "I choose the UCB value.\n",
    "\n",
    "Sample for week 4: 0.871653-0.585572"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244614d",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b23b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe59b7",
   "metadata": {},
   "source": [
    "Still not found a non-zero reading. The maximum is close to 0. The description of the function cleams that only proximity to a contamination source yield a non-zero reading.\n",
    "\n",
    "This week I am choosing to sample in the middle of the square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_point = np.array([0.5, 0.5])\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in chosen_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d8e8c",
   "metadata": {},
   "source": [
    "Submissison for week 5: 0.500000-0.500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b9d34",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a9e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645ae6b",
   "metadata": {},
   "source": [
    "Sampling the middle has yielded the best value so far, slightly positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f1_inputs[:, 0]\n",
    "x2 = f1_inputs[:, 1]\n",
    "y = np.log(f1_outputs)\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f1: Log(Output) as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f1_inputs)}\")\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f1_inputs[np.argmax(f1_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319d050",
   "metadata": {},
   "source": [
    "I am once again sampling a point with little information selected manually so that I can use those to better approximate the underlying function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed09d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_point = np.array([0.3, 0.2])\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in chosen_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453fd9c8",
   "metadata": {},
   "source": [
    "Submission for week 6: 0.300000-0.200000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1180f",
   "metadata": {},
   "source": [
    "### Week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 1\n",
    "week = 6 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f1_inputs = np.vstack([f1_inputs, row['provided_input'].values[0]])\n",
    "f1_outputs = np.append(f1_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f1_outputs):.4e}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4e}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f1_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f1_inputs):.4f}, {np.max(f1_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f1_outputs):.4e}, {np.max(f1_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ded20d",
   "metadata": {},
   "source": [
    "This week I am choosing to use another Gaussian process with an UCB aquisition function, but I am going to approximate log(y) instead of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c454751",
   "metadata": {},
   "source": [
    "## Function 2\n",
    "\n",
    "This function is a function with a 1D output and a 2D input. \n",
    "\n",
    "This is the description of the function: Imagine a black box, or a mystery ML model, that takes two numbers as input and returns a log-likelihood score. Your goal is to maximise that score, but each output is noisy, and depending on where you start, you might get stuck in a local optimum. \n",
    "\n",
    "To tackle this, you use Bayesian optimisation, which selects the next inputs based on what it has learned so far. It balances exploration with exploitation, making it well suited to noisy outputs and complex functions with many local peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6257dfe",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "This is a 2D function, so we can start by plotting the known datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c692a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f2_inputs[:, 0]\n",
    "x2 = f2_inputs[:, 1]\n",
    "y = f2_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f2: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f2_inputs)}\")\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4f}, {np.max(f2_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4e0b77",
   "metadata": {},
   "source": [
    "Data is noisy.\n",
    "\n",
    "We can try a RBF kernel combined with a WhiteKernel for noise in a Gaussian process regressor to consider that data is smooth as expected in a log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc91726",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=0.2, length_scale_bounds=(1e-10,1)) + WhiteKernel(noise_level=1e-9, noise_level_bounds=(1e-12, 1e-3))\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-8, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c=f2_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9bcce",
   "metadata": {},
   "source": [
    "Let's use a UCB acquisition function, with a choice of k = 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79387b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 2.5\n",
    "UCB = Y_mean + kappa * Y_std  # shape = (grid_size, grid_size)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X1, X2, UCB, cmap='plasma', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=50, label='Observed points')\n",
    "plt.colorbar(label='UCB acquisition value')\n",
    "plt.title(f\"UCB Acquisition Function (kappa={kappa})\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c189ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_grid[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77bd751",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.818182-0.979798\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28443e81",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a69476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 2\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f2_inputs = np.vstack([f2_inputs, row['provided_input'].values[0]])\n",
    "f2_outputs = np.append(f2_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60535067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correlation between inputs: {np.corrcoef(f2_inputs, rowvar=False)}\")\n",
    "\n",
    "print('Means:', f2_inputs.mean(axis=0))\n",
    "print('Stds:', f2_inputs.std(axis=0))\n",
    "print('Mins:', f2_inputs.min(axis=0))\n",
    "print('Maxs:', f2_inputs.max(axis=0))\n",
    "print('Std/Mean Ratios:', f2_inputs.std(axis=0) / (f2_inputs.mean(axis=0) + 1e-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d09ece",
   "metadata": {},
   "source": [
    "Let's try again a similar Gaussian process and plot the results with the new datapoint in hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118cf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=0.2, length_scale_bounds=(1e-10,1)) + WhiteKernel(noise_level=1e-9, noise_level_bounds=(1e-12, 1e-3))\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-8, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c=f2_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "kappa = 2.5\n",
    "UCB = Y_mean + kappa * Y_std  # shape = (grid_size, grid_size)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X1, X2, UCB, cmap='plasma', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=50, label='Observed points')\n",
    "plt.colorbar(label='UCB acquisition value')\n",
    "plt.title(f\"UCB Acquisition Function (kappa={kappa})\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4bad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_grid[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2fa6d",
   "metadata": {},
   "source": [
    "The acquisition function is basically suggesting to sample around already known points that are close to the maximum. As we are still on week 2, it is worth to use exploration before exploiting the known areas, especially since we are told that it is easy to get stuck at a local minimum.\n",
    "\n",
    "Let's try a different surrogate function with a penalized UCB for getting close to the borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a15761",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0, (1e-2, 10.0)) * Matern(length_scale=[1.0, 1.0], length_scale_bounds=(0.01, 10.0), nu=2.5)\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-8, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 100)\n",
    "x2 = np.linspace(0, 1, 100)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "X_grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "\n",
    "print(X_grid.shape)\n",
    "\n",
    "y_mean, y_std = gp.predict(X_grid, return_std=True)\n",
    "Y_mean = y_mean.reshape(X1.shape)\n",
    "Y_std = y_std.reshape(X1.shape)\n",
    "\n",
    "# Plot mean\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.contourf(X1, X2, Y_mean, cmap='coolwarm', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c=f2_outputs, cmap='coolwarm', edgecolor='k')\n",
    "plt.colorbar(label='Mean prediction')\n",
    "plt.title(\"GP Mean Prediction (Matern Kernel)\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "# Plot uncertainty\n",
    "plt.subplot(1,2,2)\n",
    "plt.contourf(X1, X2, Y_std, cmap='viridis', levels=50)\n",
    "plt.colorbar(label='Standard deviation (uncertainty)')\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=20)\n",
    "plt.title(\"GP Uncertainty\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "kappa = 1.5\n",
    "UCB = Y_mean + kappa * Y_std  # shape = (grid_size, grid_size)\n",
    "\n",
    "\n",
    "# Let's add a penalty for getting close to the borders\n",
    "# Calculate distance to nearest boundary for each dimension (0 and 1 here)\n",
    "min_boundary_distance = np.minimum(np.min(X_grid, axis=1), np.min(1 - X_grid, axis=1))\n",
    "\n",
    "# Penalty factor: linearly scale with distance from boundary (0 at boundary, 1 at distance >= penalty_radius)\n",
    "penalty_radius = 0.1\n",
    "penalty_factor = np.clip(min_boundary_distance / penalty_radius, 0, 1)\n",
    "\n",
    "# Apply penalty\n",
    "UCB = UCB.reshape(100, 100)\n",
    "penalty_factor = penalty_factor.reshape(100, 100)\n",
    "UCB_penalized = UCB * penalty_factor\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X1, X2, UCB_penalized, cmap='plasma', levels=50)\n",
    "plt.scatter(f2_inputs[:,0], f2_inputs[:,1], c='k', s=50, label='Observed points')\n",
    "plt.colorbar(label='UCB acquisition value')\n",
    "plt.title(f\"UCB Acquisition Function (kappa={kappa})\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(gp.kernel_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = np.argmax(UCB_penalized)  # index of the maximum UCB\n",
    "next_point = X_grid[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ffe9c3",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.707071-0.101010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5511c06",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 2\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f2_inputs = np.vstack([f2_inputs, row['provided_input'].values[0]])\n",
    "f2_outputs = np.append(f2_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4e}, {np.max(f2_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f35b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f2_inputs[:, 0]\n",
    "x2 = f2_inputs[:, 1]\n",
    "y = f2_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f2: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f2_inputs)}\")\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4f}, {np.max(f2_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5369d",
   "metadata": {},
   "source": [
    "Even though the performance did not improve this week, we found potential for another local maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c96ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2, 0.2], nu=2.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f1_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "num_restarts = 1500 # I have incremented this until the estimation did no longer move (fixed random seed)\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 2)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc724af",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.693605-0.805808\n",
    "\n",
    "Which is along the vertical line that we found to seem to contain maxima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a794954",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 2\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f2_inputs = np.vstack([f2_inputs, row['provided_input'].values[0]])\n",
    "f2_outputs = np.append(f2_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4e}, {np.max(f2_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f2_inputs[:, 0]\n",
    "x2 = f2_inputs[:, 1]\n",
    "y = f2_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f2: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f2_inputs)}\")\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4f}, {np.max(f2_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065eadbb",
   "metadata": {},
   "source": [
    "This confirms that there is a vertical line along which the function evaluates to the highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec85d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2, 0.2], nu=2.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f1_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1), (0, 1)]\n",
    "num_restarts = 1500 # I have incremented this until the estimation did no longer move (fixed random seed)\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 2)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0277a",
   "metadata": {},
   "source": [
    "Submission for week 4: 0.688772-0.849196"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417033e2",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 2\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f2_inputs = np.vstack([f2_inputs, row['provided_input'].values[0]])\n",
    "f2_outputs = np.append(f2_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4e}, {np.max(f2_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66e57a",
   "metadata": {},
   "source": [
    "The description of the function tells us to keep exploring bayesian optimisation, so I will continue using surrogate Gaussian processes for this week with tweaked hyperparameters and still some exploration bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 2\n",
    "\n",
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2, 0.2], nu=1.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f2_inputs, f2_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 150\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    #choosing kappa 1.5\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 1.5), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41a4d8",
   "metadata": {},
   "source": [
    "Submission for week 5: 0.696738-0.300878"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d412cb6",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 2\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f2_inputs = np.vstack([f2_inputs, row['provided_input'].values[0]])\n",
    "f2_outputs = np.append(f2_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4e}, {np.max(f2_outputs):.4e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec4f6d",
   "metadata": {},
   "source": [
    "This is best than last week, and close to the currently known best, but not better than previous outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b008e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f2_inputs[:, 0]\n",
    "x2 = f2_inputs[:, 1]\n",
    "y = f2_outputs\n",
    "\n",
    "# Put data into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"x1\": x1,\n",
    "    \"x2\": x2,\n",
    "    \"y\": y\n",
    "})\n",
    "\n",
    "# Scatter plot with color encoding the output\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df, x=\"x1\", y=\"x2\", hue=\"y\", palette=\"coolwarm\", s=60, legend=False)\n",
    "plt.title(\"f2: Output as function of two inputs\")\n",
    "plt.xlabel(\"Input 1\")\n",
    "plt.ylabel(\"Input 2\")\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "norm = plt.Normalize(vmin=y.min(), vmax=y.max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "plt.colorbar(sm, ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Evaluations: {len(f2_inputs)}\")\n",
    "print(f\"Inputs shape: {f2_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f2_inputs):.4f}, {np.max(f2_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f2_outputs):.4f}, {np.max(f2_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f2_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f2_inputs[np.argmax(f2_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2172a",
   "metadata": {},
   "source": [
    "There is clearly something along the vertial line at x1 = 0.7 that indicates maxima along that axis. The max values are in the 0.6-0.7 range.\n",
    "\n",
    "Similar to what I have tried with function 1, I will just sample one random point manually. This is how I have decided to spend this week's \"bullet\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_point = np.array([0.9, 0.5])\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in chosen_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965474f",
   "metadata": {},
   "source": [
    "Sample for week 6: 0.900000-0.500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfcf952",
   "metadata": {},
   "source": [
    "## Function 3\n",
    "\n",
    "This function is a function with a 1D output and a 3D input. \n",
    "\n",
    "This is the description of the function: you’re working on a drug discovery project, testing combinations of three compounds to create a new medicine.\n",
    "\n",
    "Each experiment is stored in initial_inputs.npy as a 3D array, where each row lists the amounts of the three compounds used. After each experiment, you record the number of adverse reactions, stored in initial_outputs.npy as a 1D array.\n",
    "\n",
    "Your goal is to minimise side effects; in this competition, it is framed as maximisation by optimising a transformed output (e.g. the negative of side effects). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d796fed",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "Let's observe the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f3_inputs)\n",
    "#print(f3_outputs)\n",
    "\n",
    "print(f\"Evaluations: {len(f3_inputs)}\")\n",
    "print(f\"Inputs shape: {f3_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f3_inputs):.4f}, {np.max(f3_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f3_outputs):.4f}, {np.max(f3_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b560bb",
   "metadata": {},
   "source": [
    "And even attempt to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a22c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(f3_inputs[:,0], f3_inputs[:,1], f3_inputs[:,2], \n",
    "                c=f3_outputs, cmap='coolwarm', s=60)\n",
    "\n",
    "ax.set_xlabel(\"Compound 1\")\n",
    "ax.set_ylabel(\"Compound 2\")\n",
    "ax.set_zlabel(\"Compound 3\")\n",
    "ax.set_title(\"Initial Data: Inputs vs Output\")\n",
    "cbar = fig.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cbar.set_label(\"Output (Side effects transformed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c43861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's follow a similar approach as with the others with a Matern and WhiteKerel\n",
    "\n",
    "kernel = Matern(length_scale=[0.1, 0.1, 0.1], length_scale_bounds=(0.01, 1.0), nu=1.5) \\\n",
    "         + WhiteKernel(noise_level=1e-6)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=10)\n",
    "gp.fit(f3_inputs, f3_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5ea5f",
   "metadata": {},
   "source": [
    "Getting these warnings:\n",
    "* ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified upper bound 1.0. Increasing the bound and calling fit again may find a better value.\n",
    "* ConvergenceWarning: The optimal value found for dimension 1 of parameter k1__length_scale is close to the specified upper bound 1.0. Increasing the bound and calling fit again may find a better value.\n",
    "* ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d89c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying new hyperparameters, with wider length scale bounds, and introducing noise_level_bounds. amd more restarts optimizers, a constant kernel and wider bounds.\n",
    "\n",
    "# Let's follow a similar approach as with the others with a Matern and WhiteKerel and a Constant Kernel (because I was getting many \"close to bounds\" messages)\n",
    "\n",
    "kernel = C(1.0, (1e-5, 1e5)) * Matern(length_scale=[1.0, 1.0, 1.0], length_scale_bounds=(1e-5, 1e8), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-8, noise_level_bounds=(1e-10, 1e0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=20, random_state=42)\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "\n",
    "# And calculate over the whole cube\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3 = np.meshgrid(x1, x2, x3)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel()])\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# We will use Probability of improvement (PI) as an acquisition function with a penalty for being close to the boundary (was getting 1 1 0)\n",
    "y_max = np.max(f3_outputs)\n",
    "eta = 0.01\n",
    "z = (y_mean - y_max - eta) / (y_std + 1e-12)\n",
    "pi = stats.norm.cdf(z)\n",
    "boundary_distances = np.minimum(X_candidate, 1 - X_candidate)\n",
    "min_boundary_distance = np.min(boundary_distances, axis=1)\n",
    "boundary_penalty = np.clip(min_boundary_distance / 0.1, 0, 1)\n",
    "        \n",
    "acquisition_function = pi * boundary_penalty\n",
    "\n",
    "best_idx = np.argmax(acquisition_function)\n",
    "next_point = X_candidate[best_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "print(\"Next point to sample based on PI:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2ef8c",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.172414-0.206897-0.206897"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85632dab",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 3\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f3_inputs = np.vstack([f3_inputs, row['provided_input'].values[0]])\n",
    "f3_outputs = np.append(f3_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correlation between inputs: {np.corrcoef(f3_inputs, rowvar=False)}\")\n",
    "\n",
    "print('Means:', f3_inputs.mean(axis=0))\n",
    "print('Stds:', f3_inputs.std(axis=0))\n",
    "print('Mins:', f3_inputs.min(axis=0))\n",
    "print('Maxs:', f3_inputs.max(axis=0))\n",
    "print('Std/Mean Ratios:', f3_inputs.std(axis=0) / (f3_inputs.mean(axis=0) + 1e-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2f392",
   "metadata": {},
   "source": [
    "Let us try the same strategy again but with a UCB function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d3a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0, (1e-5, 1e5)) * Matern(length_scale=[1.0, 1.0, 1.0], length_scale_bounds=(1e-5, 1e8), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-8, noise_level_bounds=(1e-10, 1e0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=20, random_state=42)\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "\n",
    "\n",
    "print(gp.kernel_)\n",
    "#print(f3_inputs)\n",
    "\n",
    "# And calculate over the whole cube\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3 = np.meshgrid(x1, x2, x3)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel()])\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# We will use Probability of improvement (PI) as an acquisition function with a penalty for being close to the boundary (was getting 1 1 0)\n",
    "y_max = np.max(f3_outputs)\n",
    "eta = 0.01\n",
    "z = (y_mean - y_max - eta) / (y_std + 1e-12)\n",
    "pi = stats.norm.cdf(z)\n",
    "boundary_distances = np.minimum(X_candidate, 1 - X_candidate)\n",
    "min_boundary_distance = np.min(boundary_distances, axis=1)\n",
    "boundary_penalty = np.clip(min_boundary_distance / 0.1, 0, 1)\n",
    "        \n",
    "acquisition_function = pi * boundary_penalty\n",
    "\n",
    "best_idx = np.argmax(acquisition_function)\n",
    "next_point_pi = X_candidate[best_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "print(\"Next point to sample based on PI:\", next_point_pi)\n",
    "\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std  # shape = (grid_size, grid_size)\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point_ucb = X_candidate[max_idx]  # coordinates in input space\n",
    "print(\"Next point to sample based on UCB:\", next_point_ucb)\n",
    "\n",
    "\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ucb.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c256eb0",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.862069-0.137931-0.655172"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fba130",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 3\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f3_inputs = np.vstack([f3_inputs, row['provided_input'].values[0]])\n",
    "f3_outputs = np.append(f3_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f3_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f3_inputs):.4f}, {np.max(f3_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f3_outputs):.4f}, {np.max(f3_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed577de8",
   "metadata": {},
   "source": [
    "For this function I have been unable to make any improvement yet. This week I will try the same approach as for functions 1 and 2 with an EI acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernel: Matern with nu=2.5 for sharp peaks\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*3, nu=2.5)\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f3_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1), (0, 1), (0, 1)]\n",
    "num_restarts = 1500 # I have incremented this until the estimation did no longer move (fixed random seed)\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 3)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5e7e8",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.507468-0.006386-0.305268"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6da18",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 3\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f3_inputs = np.vstack([f3_inputs, row['provided_input'].values[0]])\n",
    "f3_outputs = np.append(f3_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f3_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f3_inputs):.4f}, {np.max(f3_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f3_outputs):.4f}, {np.max(f3_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79325631",
   "metadata": {},
   "source": [
    "I have yet to be able to further optimize this function beyond the known best values.\n",
    "\n",
    "I will try an RBF kernel despite the description of sharp peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b441af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 3\n",
    "\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.2]*dims, length_scale_bounds=(1e-10,1))\n",
    "\n",
    "# Instantiate GP with small noise level\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f3_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 150 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point_ei = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ei):\", next_point_ei)\n",
    "\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 150\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 1.7), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ucb):\", next_point_ucb)\n",
    "\n",
    "\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ei.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a636a21",
   "metadata": {},
   "source": [
    "I choose the EI value.\n",
    "\n",
    "Submission for week 4: 0.589937-0.603952-0.435945"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90e23a",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 3\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f3_inputs = np.vstack([f3_inputs, row['provided_input'].values[0]])\n",
    "f3_outputs = np.append(f3_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f3_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f3_inputs):.4f}, {np.max(f3_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f3_outputs):.4f}, {np.max(f3_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae96298",
   "metadata": {},
   "source": [
    "This is a near 0 value! Remember that 0 is the goal. This week's submission should be focused on exploitation of this area. Last week we chose the highest EI, let's replicate the same again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 3\n",
    "\n",
    "#kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.2]*dims, length_scale_bounds=(1e-10,10))\n",
    "#kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*dims, nu=1.5) + C(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.2]*dims, length_scale_bounds=(1e-10,1))\n",
    "\n",
    "kernel = C(1.0, (1e-5, 1e5)) * Matern(length_scale=[1.0, 1.0, 1.0], length_scale_bounds=(1e-5, 1e8), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-8, noise_level_bounds=(1e-10, 1e0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=20, random_state=42)\n",
    "# Instantiate GP with small noise level\n",
    "#gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f3_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-12)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 250 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point_ei = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ei):\", next_point_ei)\n",
    "\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 250\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 0.4), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ucb):\", next_point_ucb)\n",
    "\n",
    "\n",
    "x1 = np.linspace(0, 1, 50)\n",
    "x2 = np.linspace(0, 1, 50)\n",
    "x3 = np.linspace(0, 1, 50)\n",
    "X1, X2, X3 = np.meshgrid(x1, x2, x3)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel()])\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# We will use Probability of improvement (PI) as an acquisition function with a penalty for being close to the boundary (was getting 1 1 0)\n",
    "y_max = np.max(f3_outputs)\n",
    "eta = 0.01\n",
    "z = (y_mean - y_max - eta) / (y_std + 1e-12)\n",
    "pi = stats.norm.cdf(z)\n",
    "boundary_distances = np.minimum(X_candidate, 1 - X_candidate)\n",
    "min_boundary_distance = np.min(boundary_distances, axis=1)\n",
    "boundary_penalty = np.clip(min_boundary_distance / 0.1, 0, 1)\n",
    "        \n",
    "acquisition_function = pi * boundary_penalty\n",
    "\n",
    "best_idx = np.argmax(acquisition_function)\n",
    "next_point_pi = X_candidate[best_idx]\n",
    "\n",
    "print(\"Next sample point (pi):\", next_point_pi)\n",
    "\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ei.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c99a2",
   "metadata": {},
   "source": [
    "Submission for week 5: 0.593114-0.448446-0.293211"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87d588",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe340ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 3\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f3_inputs = np.vstack([f3_inputs, row['provided_input'].values[0]])\n",
    "f3_outputs = np.append(f3_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f3_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f3_inputs):.4f}, {np.max(f3_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f3_outputs):.4f}, {np.max(f3_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d576c7",
   "metadata": {},
   "source": [
    "I will try again the same strategy as we are very close to 0. EI as aquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 3\n",
    "\n",
    "#kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.2]*dims, length_scale_bounds=(1e-10,10))\n",
    "#kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*dims, nu=1.5) + C(1.0, (1e-3, 1e3)) * RBF(length_scale=[0.2]*dims, length_scale_bounds=(1e-10,1))\n",
    "\n",
    "kernel = C(1.0, (1e-5, 1e5)) * Matern(length_scale=[1.0, 1.0, 1.0], length_scale_bounds=(1e-5, 1e8), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-8, noise_level_bounds=(1e-10, 1e0))\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True, n_restarts_optimizer=20, random_state=42)\n",
    "# Instantiate GP with small noise level\n",
    "#gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-3, normalize_y=True)\n",
    "\n",
    "# Fit the GP model\n",
    "gp.fit(f3_inputs, f3_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "\n",
    "# Function to optimize acquisition: Expected Improvement\n",
    "def acquisitionf(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f3_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-12)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "# Robust acquisition maximization via multi-start local optimization\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 250 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    res = minimize(acquisitionf, x0, bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4e}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "\n",
    "# Select best solution from restarts\n",
    "next_point_ei = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ei):\", next_point_ei)\n",
    "\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 250\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 0.4), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (ucb):\", next_point_ucb)\n",
    "\n",
    "\n",
    "x1 = np.linspace(0, 1, 50)\n",
    "x2 = np.linspace(0, 1, 50)\n",
    "x3 = np.linspace(0, 1, 50)\n",
    "X1, X2, X3 = np.meshgrid(x1, x2, x3)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel()])\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# We will use Probability of improvement (PI) as an acquisition function with a penalty for being close to the boundary (was getting 1 1 0)\n",
    "y_max = np.max(f3_outputs)\n",
    "eta = 0.01\n",
    "z = (y_mean - y_max - eta) / (y_std + 1e-12)\n",
    "pi = stats.norm.cdf(z)\n",
    "boundary_distances = np.minimum(X_candidate, 1 - X_candidate)\n",
    "min_boundary_distance = np.min(boundary_distances, axis=1)\n",
    "boundary_penalty = np.clip(min_boundary_distance / 0.1, 0, 1)\n",
    "        \n",
    "acquisition_function = pi * boundary_penalty\n",
    "\n",
    "best_idx = np.argmax(acquisition_function)\n",
    "next_point_pi = X_candidate[best_idx]\n",
    "\n",
    "print(\"Next sample point (pi):\", next_point_pi)\n",
    "\n",
    "\n",
    "print(f\"Current best: {np.max(f3_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f3_inputs[np.argmax(f3_outputs)]}\")\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ei.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc89bc92",
   "metadata": {},
   "source": [
    "Submission for week 6: 0.587870-0.097176-0.615007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc9efb",
   "metadata": {},
   "source": [
    "## Function 4\n",
    "\n",
    "This function is a function with a 1D output and a 4D input. \n",
    "\n",
    "This is the description of the function: Address the challenge of optimally placing products across warehouses for a business with high online sales, where accurate calculations are costly and only feasible biweekly. To speed up decision-making, an ML model approximates these results within hours. The model has four hyperparameters to tune, and its output reflects the difference from the expensive baseline. Because the system is dynamic and full of local optima, it requires careful tuning and robust validation to find reliable, near-optimal solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b922520c",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "It is no longer viable to plot anything, so let's just look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1079fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations: {len(f4_inputs)}\")\n",
    "print(f\"Inputs shape: {f4_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f4_inputs):.4f}, {np.max(f4_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f4_outputs):.4f}, {np.max(f4_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223113e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (C(1.0, (1e-3, 1e3)) * Matern(length_scale=[2.0]*4, length_scale_bounds=(0.1, 1000.0), nu=2.5) + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-15, 1e-1)))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "mu, sigma = gp.predict(X_candidate, return_std=True)\n",
    "best = np.max(f4_outputs)\n",
    "xi = 0.01\n",
    "z = (mu - best - xi) / (sigma + 1e-12)\n",
    "ei = (mu - best - xi) * stats.norm.cdf(z) + sigma * stats.norm.pdf(z)\n",
    "ei\n",
    "\n",
    "best_idx = np.argmax(ei)\n",
    "next_point = X_candidate[best_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n",
    "print(\"Next point to sample based on PI:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da7ed1",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.448276-0.413793-0.379310-0.379310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a30e2c",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 4\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f4_inputs = np.vstack([f4_inputs, row['provided_input'].values[0]])\n",
    "f4_outputs = np.append(f4_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85148638",
   "metadata": {},
   "source": [
    "This yielded a very good improvement. Let's replicate the method again this week, including the EI function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (C(1.0, (1e-3, 1e3)) * Matern(length_scale=[2.0]*4, length_scale_bounds=(0.1, 1000.0), nu=2.5) + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-15, 1e-1)))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "mu, sigma = gp.predict(X_candidate, return_std=True)\n",
    "best = np.max(f4_outputs)\n",
    "xi = 0.01\n",
    "z = (mu - best - xi) / (sigma + 1e-12)\n",
    "ei = (mu - best - xi) * stats.norm.cdf(z) + sigma * stats.norm.pdf(z)\n",
    "\n",
    "best_idx = np.argmax(ei)\n",
    "next_point = X_candidate[best_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n",
    "print(\"Next point to sample based on PI:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cc9b1",
   "metadata": {},
   "source": [
    "The kernel is very balanced in terms of length scale for each dimension.\n",
    "\n",
    "Submission for week 2: 0.413793-0.413793-0.344828-0.413793"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc34ec4",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a571ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 4\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f4_inputs = np.vstack([f4_inputs, row['provided_input'].values[0]])\n",
    "f4_outputs = np.append(f4_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f4_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f4_inputs):.4f}, {np.max(f4_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f4_outputs):.4f}, {np.max(f4_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc54ee",
   "metadata": {},
   "source": [
    "While this is the second improvement in a row, this function 4 has been sampled around the same point for two weeks in a row already.  This is encouraging exploitation. This week, for a change, I am using a UCB kernel encouraging exploration to see if I can find another local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d579fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (C(1.0, (1e-3, 1e3)) * Matern(length_scale=[2.0]*4, length_scale_bounds=(0.1, 1000.0), nu=2.5) + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-15, 1e-1)))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(4)]\n",
    "num_restarts = 50 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 4)\n",
    "    #choosing kappa 3.7 to encourage exploration\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, 4), \n",
    "                 args=(gp, 3.7), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947882e1",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.471861-0.446201-0.136768-0.434511\n",
    "\n",
    "This is still exploiting this area. Next week I will just sample the point furthest from all known samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e446a",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 4\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f4_inputs = np.vstack([f4_inputs, row['provided_input'].values[0]])\n",
    "f4_outputs = np.append(f4_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f4_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f4_inputs):.4f}, {np.max(f4_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f4_outputs):.4f}, {np.max(f4_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e85d4a",
   "metadata": {},
   "source": [
    "This week the goal is just to sample the point that is further away from all known points to try and find another local minimum as the function descriptions describes it as having many and my strategy so far has been on exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd443826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the minimum distance from a given point to the set of known points\n",
    "def min_distance_to_points(point, points):\n",
    "    # Compute pairwise distances between the point and each of the known points\n",
    "    distances = cdist([point], points)\n",
    "    # Return the minimum distance (further away from the closest point)\n",
    "    return np.min(distances)\n",
    "\n",
    "# Objective function to maximize the minimum distance\n",
    "def objective_function(point, points):\n",
    "    # We want to maximize the minimum distance, so we return the negative of the minimum distance\n",
    "    return -min_distance_to_points(point, points)\n",
    "\n",
    "# Bounds for the variables (each dimension is within [0,1])\n",
    "bounds = [(0, 1)] * 4\n",
    "num_restarts = 150\n",
    "results = []\n",
    "# Initial guess (can be any point in the space, e.g., the center of the space)\n",
    "np.random.seed(42)\n",
    "initial_guess = np.random.uniform(0, 1, 4)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    res = minimize(objective_function, initial_guess, args=(f4_inputs,), bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "# The resulting point is the one furthest from all known points\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n",
    "print(\"Next sample point (furthest point from known data):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b9190",
   "metadata": {},
   "source": [
    "This is clearly one corner that I am choosing to explore.\n",
    "\n",
    "Submission for week 4: 0.571931-1.000000-1.000000-0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec8a8c",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891862f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 4\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f4_inputs = np.vstack([f4_inputs, row['provided_input'].values[0]])\n",
    "f4_outputs = np.append(f4_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f4_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f4_inputs):.4f}, {np.max(f4_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f4_outputs):.4f}, {np.max(f4_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ce995",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4_inputs_outputs = np.hstack([f4_inputs, f4_outputs.reshape(f4_inputs.shape[0],1)])\n",
    "#print(f4_inputs_outputs)\n",
    "\n",
    "print(f\"Correlation between inputs and with outputs (last column): \\n{np.corrcoef(f4_inputs_outputs, rowvar=False)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d37a57",
   "metadata": {},
   "source": [
    "There is a negative correlation between all the inputs and the outputs.\n",
    "\n",
    "Let's remember that this function is full of local optima. Because we are still in week 5, we can affort to explore a bit more.\n",
    "\n",
    "I will try a dimensionality-reduction technique to plot and visualize what we`ve got so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af378dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)\n",
    "f4_inputs_3d = pca.fit_transform(f4_inputs)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18d776",
   "metadata": {},
   "source": [
    "So three dimentions explain about 0.35 + 0.30 + 0.22 = 0.87 of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c01be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(f4_inputs_3d[:,0], f4_inputs_3d[:,1], f4_inputs_3d[:,2], \n",
    "                c=f4_outputs, cmap='coolwarm', s=60)\n",
    "\n",
    "ax.set_xlabel(\"z1\")\n",
    "ax.set_ylabel(\"z2\")\n",
    "ax.set_zlabel(\"z3\")\n",
    "ax.set_title(\"F4 3D dim reduction z components\")\n",
    "cbar = fig.colorbar(sc, ax=ax, shrink=0.6)\n",
    "cbar.set_label(\"Output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e884591",
   "metadata": {},
   "source": [
    "No local minima are observed but rather a cluster of values close to the maximum. \n",
    "\n",
    "I wanted to explore using a neural network this week, but given the results I think there is still some value in using a Gaussian process as a surrogate function once again considering the new extreme data point from last week.\n",
    "\n",
    "Let's first explore where the furthest point lies now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b65785",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_restarts = 250\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    res = minimize(objective_function, initial_guess, args=(f4_inputs,), bounds=bounds, method='L-BFGS-B')\n",
    "    results.append(res)\n",
    "\n",
    "# The resulting point is the one furthest from all known points\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(\"Current furthest point from known data:\", next_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fe649",
   "metadata": {},
   "source": [
    "No need to explore another corner. Let's use a GP with a Matern kernel and a softer nu. Still UCB, with a heavily exploratory kappa parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 4\n",
    "\n",
    "kernel = (C(1.0, (1e-3, 1e3)) * Matern(length_scale=[2.0]*dims, length_scale_bounds=(0.1, 1000.0), nu=1.5) + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-15, 1e-1)))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "num_restarts = 50 \n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, dims)\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "                 args=(gp, 3.5), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f4_inputs[np.argmax(f4_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a0d88",
   "metadata": {},
   "source": [
    "Submission for week 5: 0.305616-0.434746-0.456803-0.473341"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f97385",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 4\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f4_inputs = np.vstack([f4_inputs, row['provided_input'].values[0]])\n",
    "f4_outputs = np.append(f4_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f4_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f4_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f4_inputs):.4f}, {np.max(f4_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f4_outputs):.4f}, {np.max(f4_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42538c1",
   "metadata": {},
   "source": [
    "## Function 5\n",
    "\n",
    "This function is a function with a 1D output and a 4D input. \n",
    "\n",
    "This is the description of the function: You’re tasked with optimising a four-variable black-box function that represents the yield of a chemical process in a factory. The function is typically unimodal, with a single peak where yield is maximised. \n",
    "\n",
    "Your goal is to find the optimal combination of chemical inputs that delivers the highest possible yield, using systematic exploration and optimisation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ad248",
   "metadata": {},
   "source": [
    "### Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb49739",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations: {len(f5_inputs)}\")\n",
    "print(f\"Inputs shape: {f5_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f5_inputs):.4f}, {np.max(f5_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f5_outputs):.4f}, {np.max(f5_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265707af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is unimodal with a single peak, so I am choosing an RBF kernel\n",
    "kernel = RBF(length_scale=[1.0] * 4, length_scale_bounds=(0.05, 15000.0)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=15,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f5_inputs, f5_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 2.0\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f02d1",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.586207-0.620690-1.000000-0.931034\n",
    "\n",
    "It is noted that I am one value at one of the bounds, will explore next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e6f82",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 5\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f5_inputs = np.vstack([f5_inputs, row['provided_input'].values[0]])\n",
    "f5_outputs = np.append(f5_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8654b25",
   "metadata": {},
   "source": [
    "This yielded a very good improvement, what this function maximum is is unknown.\n",
    "\n",
    "Let's replicate again the same method this week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee9b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is unimodal with a single peak, so I am choosing an RBF kernel\n",
    "kernel = RBF(length_scale=[1.0] * 4, length_scale_bounds=(0.05, 15000.0)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=15,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f5_inputs, f5_outputs)\n",
    "\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62c2be",
   "metadata": {},
   "source": [
    "This would be encouraging sampling on a corner. While I may try this once, I will first try for this week's submission:\n",
    "* Reducing the boundaries so that extreme values are not suggested.\n",
    "* A denser mesh as 4 dimensions is still manageable.\n",
    "* A penalty for being close to the borders (not linear but harsh around the border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to avoid sampling exactly at the edges\n",
    "x1 = np.linspace(0.05, 0.95, 50)\n",
    "x2 = np.linspace(0.05, 0.95, 50)\n",
    "x3 = np.linspace(0.05, 0.95, 50)\n",
    "x4 = np.linspace(0.05, 0.95, 50)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std\n",
    "#edge_penalty = 0.5 * ((X_candidate < 0.07) | (X_candidate > 0.93)).sum(axis=1)\n",
    "#UCB_adjusted = UCB - edge_penalty\n",
    "\n",
    "# Let's add a penalty for getting close to the borders\n",
    "# Calculate distance to nearest boundary for each dimension (0 and 1 here)\n",
    "min_boundary_distance = np.minimum(np.min(X_candidate, axis=1), np.min(1 - X_candidate, axis=1))\n",
    "min_boundary_distance.shape\n",
    "\n",
    "# Penalty factor: linearly scale with distance from boundary (0 at boundary, 1 at distance >= penalty_radius)\n",
    "penalty_radius = 0.1\n",
    "penalty_factor = np.clip(min_boundary_distance / penalty_radius, 0, 1)\n",
    "\n",
    "# Apply penalty\n",
    "UCB_penalized = UCB * penalty_factor\n",
    "\n",
    "max_idx = np.argmax(UCB_penalized)\n",
    "next_point_2 = X_candidate[max_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb1a4c",
   "metadata": {},
   "source": [
    "Considering this, I will choose to sample the extreme this week and, depending on the result, reevaluate next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Next point to sample based on UCB:\", next_point_2)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_2.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0028a",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.894898-0.105102-0.894898-0.894898"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558103e",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40369a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 5\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f5_inputs = np.vstack([f5_inputs, row['provided_input'].values[0]])\n",
    "f5_outputs = np.append(f5_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f5_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f5_inputs):.4f}, {np.max(f5_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f5_outputs):.4f}, {np.max(f5_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a98fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switching to Mattern kernel\n",
    " \n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*4, nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-8, 1e0))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(4)]\n",
    "num_restarts = 50\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 4)\n",
    "    #choosing kappa 2.7 \n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, 4), \n",
    "                 args=(gp, 2.7), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfddcd9",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.452640-0.433354-0.202919-0.441704"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510dc9e1",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5571a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 5\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f5_inputs = np.vstack([f5_inputs, row['provided_input'].values[0]])\n",
    "f5_outputs = np.append(f5_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f5_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f5_inputs):.4f}, {np.max(f5_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f5_outputs):.4f}, {np.max(f5_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33491ab4",
   "metadata": {},
   "source": [
    "This is not an improvement, but this allows me to capture yet another datapoint that will be useful.\n",
    "\n",
    "I am choosing to apply the same methodology once again this week, but reverting to an RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68b3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switching to Mattern kernel\n",
    "\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=[1.0] * 4, length_scale_bounds=(0.05, 15000.0)) \n",
    "#kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[0.2]*4, nu=2.5) \\\n",
    "#         + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-8, 1e0))\n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f4_inputs, f4_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "bounds = [(0, 1) for _ in range(4)]\n",
    "num_restarts = 150\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    x0 = np.random.uniform(0, 1, 4)\n",
    "    #choosing kappa 1.5\n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, 4), \n",
    "                 args=(gp, 1.5), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer):\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3455e4",
   "metadata": {},
   "source": [
    "Submission for week 4: 0.017701-0.472569-0.492069-0.597183"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09d760",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc0f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 5\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f5_inputs = np.vstack([f5_inputs, row['provided_input'].values[0]])\n",
    "f5_outputs = np.append(f5_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f5_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f5_inputs):.4f}, {np.max(f5_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f5_outputs):.4f}, {np.max(f5_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5_inputs_outputs = np.hstack([f5_inputs, f5_outputs.reshape(f5_inputs.shape[0],1)])\n",
    "#print(f5_inputs_outputs)\n",
    "\n",
    "print(f\"Correlation between inputs and with outputs (last column): \\n{np.corrcoef(f5_inputs_outputs, rowvar=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178bdf6c",
   "metadata": {},
   "source": [
    "Results were better with a RBF kernel. Function is unimodal and there is a single peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf124a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is unimodal with a single peak, so I am choosing an RBF kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=[1.0] * 4, length_scale_bounds=(0.05, 15000.0)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=25,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f5_inputs, f5_outputs)\n",
    "\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4 = np.meshgrid(x1, x2, x3, x4)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 0.3\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f5_inputs[np.argmax(f5_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3d556",
   "metadata": {},
   "source": [
    "Submission for week 5: 1.000000-0.000000-1.000000-0.965517"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f73be",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 5\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f5_inputs = np.vstack([f5_inputs, row['provided_input'].values[0]])\n",
    "f5_outputs = np.append(f5_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f5_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f5_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f5_inputs):.4f}, {np.max(f5_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f5_outputs):.4f}, {np.max(f5_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4807b4",
   "metadata": {},
   "source": [
    "## Function 6\n",
    "\n",
    "This function is a function with a 1D output and a 5D input. \n",
    "\n",
    "This is the description of the function: You’re optimising a cake recipe using a black-box function with five ingredient inputs, for example flour, sugar, eggs, butter and milk. Each recipe is evaluated with a combined score based on flavour, consistency, calories, waste and cost, where each factor contributes negative points as judged by an expert taster. This means the total score is negative by design. \n",
    "\n",
    "To frame this as a maximisation problem, your goal is to bring that score as close to zero as possible or, equivalently, to maximise the negative of the total sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973abfa",
   "metadata": {},
   "source": [
    "### Week 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations: {len(f6_inputs)}\")\n",
    "print(f\"Inputs shape: {f6_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f6_inputs):.4f}, {np.max(f6_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f6_outputs):.4f}, {np.max(f6_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d0c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=[1.0] * 5, length_scale_bounds=(0.05, 15000.0)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=15,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f6_inputs, f6_outputs)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "x5 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4, X5 = np.meshgrid(x1, x2, x3, x4, x5)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel(), X5.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 2.0\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46ccff",
   "metadata": {},
   "source": [
    "Submission for week 1 0.000000-0.655172-0.103448-0.931034-0.275862\n",
    "\n",
    "It is noted that I am one value at one of the bounds, will explore next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6925926",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 6\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f6_inputs = np.vstack([f6_inputs, row['provided_input'].values[0]])\n",
    "f6_outputs = np.append(f6_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e92b78",
   "metadata": {},
   "source": [
    "The ideal score is zero, which we are still far from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adb045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correlation between inputs: \\n{np.corrcoef(f6_inputs, rowvar=False)}\\n\")\n",
    "\n",
    "print('Means:', f6_inputs.mean(axis=0))\n",
    "print('Stds:', f6_inputs.std(axis=0))\n",
    "print('Mins:', f6_inputs.min(axis=0))\n",
    "print('Maxs:', f6_inputs.max(axis=0))\n",
    "print('Std/Mean Ratios:', f6_inputs.std(axis=0) / (f6_inputs.mean(axis=0) + 1e-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48deebf4",
   "metadata": {},
   "source": [
    "Let's try to get a better fit of a surrogate function and willingly limit the upper bound of length scale, and a smaller kappa for UCB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aef24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is unimodal with a single peak, so I am choosing an RBF kernel\n",
    "kernel = RBF(length_scale=[1.0] * 5, length_scale_bounds=(0.05, 15)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=15,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f6_inputs, f6_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "x5 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4, X5 = np.meshgrid(x1, x2, x3, x4, x5)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel(), X5.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n",
    "\n",
    "#print(f6_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9466da1",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.517241-0.310345-0.517241-0.862069-0.103448"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f572cd",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 6\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f6_inputs = np.vstack([f6_inputs, row['provided_input'].values[0]])\n",
    "f6_outputs = np.append(f6_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f6_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f6_inputs):.4f}, {np.max(f6_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f6_outputs):.4f}, {np.max(f6_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=[1.0] * 5, length_scale_bounds=(0.05, 15)) \n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f6_inputs, f6_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "def neg_ei(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f6_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "\n",
    "bounds = [(0, 1) for _ in range(5)]\n",
    "num_restarts = 100\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    #choosing kappa 2.7 \n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, 5), \n",
    "                 args=(gp, 2.7), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer) based on UCB:\", next_point)\n",
    "\n",
    "num_restarts = 50\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    #choosing kappa 2.7 \n",
    "    result = minimize(neg_ei, x0=np.random.uniform(0, 1, 5), \n",
    "                 bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "\n",
    "next_point = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer) based on EI:\", next_point)\n",
    "\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a27d1",
   "metadata": {},
   "source": [
    "I choose the EI point.\n",
    "\n",
    "Submission for week 3: 0.493775-0.266439-0.665329-1.000000-0.266425"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d14e0c6",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 6\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f6_inputs = np.vstack([f6_inputs, row['provided_input'].values[0]])\n",
    "f6_outputs = np.append(f6_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f6_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f6_inputs):.4f}, {np.max(f6_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f6_outputs):.4f}, {np.max(f6_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ba30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=[1.0] * 5, length_scale_bounds=(0.05, 15)) \n",
    "gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=1e-6,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=30,\n",
    "        random_state=42\n",
    "    )\n",
    "gp.fit(f6_inputs, f6_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "def neg_ei(x):\n",
    "    x = np.array(x).reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # Current best observation\n",
    "    best_y = np.max(f6_outputs)\n",
    "    # Calculate EI\n",
    "    z = (mean - best_y) / (std + 1e-9)\n",
    "    ei = (mean - best_y) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    return -ei.item()  \n",
    "\n",
    "\n",
    "bounds = [(0, 1) for _ in range(5)]\n",
    "num_restarts = 100\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    #choosing kappa 2.7 \n",
    "    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, 5), \n",
    "                 args=(gp, 1.2), bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "print(\"Next sample point (local optimizer) based on UCB:\", next_point_ucb)\n",
    "\n",
    "num_restarts = 200\n",
    "results = []\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(num_restarts):\n",
    "    result = minimize(neg_ei, x0=np.random.uniform(0, 1, 5), \n",
    "                 bounds=bounds, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        results.append(result)\n",
    "\n",
    "next_point_ei = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n",
    "print(\"Next sample point (local optimizer) based on EI:\", next_point_ei)\n",
    "\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ucb.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3506f",
   "metadata": {},
   "source": [
    "I choose the UCB estimate.\n",
    "\n",
    "Submission for week 4: 0.482310-0.418871-0.201310-0.981559-0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8027529",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f154d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 6\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f6_inputs = np.vstack([f6_inputs, row['provided_input'].values[0]])\n",
    "f6_outputs = np.append(f6_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f6_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f6_inputs):.4f}, {np.max(f6_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f6_outputs):.4f}, {np.max(f6_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6_inputs_outputs = np.hstack([f6_inputs, f6_outputs.reshape(f6_inputs.shape[0],1)])\n",
    "#print(f6_inputs_outputs)\n",
    "\n",
    "print(f\"Correlation between inputs and with outputs (last column): \\n{np.corrcoef(f6_inputs_outputs, rowvar=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee7900",
   "metadata": {},
   "source": [
    "Let us replicate what was done on week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is unimodal with a single peak, so I am choosing an RBF kernel\n",
    "kernel = C(1.0, (1e-6, 1e6)) * RBF(length_scale=[1.0] * 5, length_scale_bounds=(0.05, 15)) \n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=15,\n",
    "    alpha=1e-6, #modelling noise     \n",
    "    normalize_y=True,\n",
    "    random_state=42\n",
    ")\n",
    "gp.fit(f6_inputs, f6_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "x1 = np.linspace(0, 1, 30)\n",
    "x2 = np.linspace(0, 1, 30)\n",
    "x3 = np.linspace(0, 1, 30)\n",
    "x4 = np.linspace(0, 1, 30)\n",
    "x5 = np.linspace(0, 1, 30)\n",
    "X1, X2, X3, X4, X5 = np.meshgrid(x1, x2, x3, x4, x5)\n",
    "X_candidate = np.column_stack([X1.ravel(), X2.ravel(), X3.ravel(), X4.ravel(), X5.ravel()])\n",
    "\n",
    "# Expected improvement\n",
    "y_mean, y_std = gp.predict(X_candidate, return_std=True)\n",
    "\n",
    "# The fact that the function has a single peak also makes me avoid PI, and a simple UCB should be fine\n",
    "kappa = 0.3\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "max_idx = np.argmax(UCB)  # index of the maximum UCB\n",
    "next_point = X_candidate[max_idx]  # coordinates in input space\n",
    "\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f6_inputs[np.argmax(f6_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n",
    "\n",
    "#print(f6_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d8956",
   "metadata": {},
   "source": [
    "Submission for week 5: 0.241379-0.310345-0.689655-0.931034-0.103448"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8396719",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 6\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f6_inputs = np.vstack([f6_inputs, row['provided_input'].values[0]])\n",
    "f6_outputs = np.append(f6_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f6_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f6_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f6_inputs):.4f}, {np.max(f6_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f6_outputs):.4f}, {np.max(f6_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a618b47",
   "metadata": {},
   "source": [
    "## Function 7\n",
    "\n",
    "This function is a function with a 1D output and a 6D input. \n",
    "\n",
    "This is the description of the function: You’re tasked with optimising an ML model by tuning six hyperparameters, for example learning rate, regularisation strength or number of hidden layers. The function you’re maximising is the model’s performance score (such as accuracy or F1), but since the relationship between inputs and output isn’t known, it’s treated as a black-box function. \n",
    "\n",
    "Because this is a commonly used model, you might benefit from researching best practices or literature to guide your initial search space. Your goal is to find the combination of hyperparameters that yields the highest possible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7358b4c",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "The problem statement is similar to function 2, but with more dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations: {len(f7_inputs)}\")\n",
    "print(f\"Inputs shape: {f7_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f7_inputs):.4f}, {np.max(f7_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f7_outputs):.4f}, {np.max(f7_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f7_inputs[np.argmax(f7_outputs)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35841a2a",
   "metadata": {},
   "source": [
    "\n",
    "There is not known relationship between the parameters and the output. I will try a combination of Mattern, Constant, RBF and White with UCB as adcquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc280ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (\n",
    "    C(1.0, (1e-6, 1e6)) * (\n",
    "        RBF([1.0]*6, length_scale_bounds=(1e-2, 1e10)) +\n",
    "        Matern(length_scale=[1.0]*6, length_scale_bounds=(1e-2,1e13), nu=2.5)\n",
    "    ) +\n",
    "    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f7_inputs, f7_outputs)\n",
    "\n",
    "margin = 0.01  # avoid boundaries, previous function gave a 1 for one of the coordinates\n",
    "#grid_points = 18 # to be able to lower it as we're exploring grip_points^6, 20 was giving memory errors\n",
    "#axes = [np.linspace(margin, 1-margin, grid_points) for _ in range(6)]\n",
    "#mesh = np.meshgrid(*axes) # instead of doing this 6 times\n",
    "#X_candidates = np.column_stack([arr.ravel() for arr in mesh])\n",
    "\n",
    "#y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "n_candidates = 1000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 6)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 2.5 \n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f7_inputs[np.argmax(f7_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a5d04",
   "metadata": {},
   "source": [
    "Submission for the week: 0.014182-0.276863-0.738085-0.053110-0.375860-0.799450"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41639d",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e317b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 7\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f7_inputs = np.vstack([f7_inputs, row['provided_input'].values[0]])\n",
    "f7_outputs = np.append(f7_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6bb4e",
   "metadata": {},
   "source": [
    "Marginal improvement as compared to last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correlation between inputs: \\n{np.corrcoef(f7_inputs, rowvar=False)}\\n\")\n",
    "\n",
    "print('Means:', f7_inputs.mean(axis=0))\n",
    "print('Stds:', f7_inputs.std(axis=0))\n",
    "print('Mins:', f7_inputs.min(axis=0))\n",
    "print('Maxs:', f7_inputs.max(axis=0))\n",
    "print('Std/Mean Ratios:', f7_inputs.std(axis=0) / (f7_inputs.mean(axis=0) + 1e-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (\n",
    "    C(1.0, (1e-2, 1e2)) * (\n",
    "        RBF([1.0]*6, length_scale_bounds=(1e-2, 3)) +\n",
    "        Matern(length_scale=[1.0]*6, length_scale_bounds=(1e-2,1e2), nu=2.5)\n",
    "    ) +\n",
    "    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f7_inputs, f7_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "n_candidates = 3000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "margin=0.01\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 6)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 0.5 \n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f7_inputs[np.argmax(f7_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5181d0",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.016974-0.324003-0.154628-0.172541-0.388943-0.758898"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dd470",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 7\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f7_inputs = np.vstack([f7_inputs, row['provided_input'].values[0]])\n",
    "f7_outputs = np.append(f7_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f7_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f7_inputs):.4f}, {np.max(f7_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f7_outputs):.4f}, {np.max(f7_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f74c4",
   "metadata": {},
   "source": [
    "The improvement is more significant this week. We can have another go at the same strategy once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a286939",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = (\n",
    "    C(1.0, (1e-2, 1e2)) * (\n",
    "        RBF([1.0]*6, length_scale_bounds=(1e-2, 15)) +\n",
    "        Matern(length_scale=[1.0]*6, length_scale_bounds=(1e-2,250), nu=2.5)\n",
    "    ) +\n",
    "    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f7_inputs, f7_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "\n",
    "bounds = [(0, 1) for _ in range(6)]\n",
    "\n",
    "n_candidates = 3000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "margin=0.01\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 6)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 0.5 \n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f7_inputs[np.argmax(f7_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035f319",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.015145-0.204820-0.115783-0.977408-0.415003-0.770445"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06523f62",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 7\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f7_inputs = np.vstack([f7_inputs, row['provided_input'].values[0]])\n",
    "f7_outputs = np.append(f7_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f7_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f7_inputs):.4f}, {np.max(f7_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f7_outputs):.4f}, {np.max(f7_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48200f",
   "metadata": {},
   "source": [
    "No improvement this week. I am choosing a more simplified kernel and a UCB acquisition function to further explore this high-dimensional space for the week. I am also simplifying the kernel and switching to Sobol sampling, which is supposed to cover better this high-dimensional space (https://en.wikipedia.org/wiki/Sobol_sequence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb658df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C(1.0, (1e-2, 1e2)) * Matern(length_scale=[1.0]*6, length_scale_bounds=(1e-2, 300), nu=2.5) + \\\n",
    "         WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    "\n",
    "#kernel = (\n",
    "#    C(1.0, (1e-3, 1e3)) *\n",
    "#    (\n",
    "#        RBF(length_scale=[1.0]*6, length_scale_bounds=(1e-2, 75)) +\n",
    "#        Matern(length_scale=[1.0]*6, length_scale_bounds=(1e-2, 1000), nu=2.5)\n",
    "#    ) +\n",
    "#    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    "#)\n",
    "\n",
    "gp = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True,\n",
    "    n_restarts_optimizer=40,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gp.fit(f7_inputs, f7_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "def negative_ucb(x, gp, kappa):\n",
    "    mu, sigma = gp.predict(x.reshape(1, -1), return_std=True)\n",
    "    return -(mu[0] + kappa * sigma[0])\n",
    "\n",
    "dims = 6\n",
    "bounds = [(0, 1) for _ in range(dims)]\n",
    "\n",
    "\n",
    "#num_restarts = 5000\n",
    "#results = []\n",
    "#np.random.seed(42)\n",
    "\n",
    "#for _ in range(num_restarts):\n",
    "#    x0 = np.random.uniform(0, 1, dims)\n",
    "#    result = minimize(negative_ucb, x0=np.random.uniform(0, 1, dims), \n",
    "#                 args=(gp, 1.2), bounds=bounds, method='L-BFGS-B')\n",
    "#    if result.success:\n",
    "#        results.append(result)\n",
    "    \n",
    "# Select best solution from restarts\n",
    "#next_point_ucb = min(results, key=lambda r: r.fun).x\n",
    "\n",
    "n_candidates = 500000  # efficient but large enough\n",
    "margin = 0.01\n",
    "\n",
    "sampler = qmc.Sobol(d=dims, scramble=True, seed=42)\n",
    "X_candidates = sampler.random(n_candidates)\n",
    "X_candidates = margin + (1 - 2 * margin) * X_candidates  # stay inside (margin, 1-margin)\n",
    "\n",
    "# Predict GP mean and std for all candidates\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# Dynamic exploration factor\n",
    "# Example: if you've done t of 5 remaining steps, gradually reduce kappa\n",
    "t = len(f7_inputs)  # number of samples so far\n",
    "kappa = 1.5\n",
    "\n",
    "# UCB acquisition\n",
    "UCB = y_mean + kappa * y_std\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point_ucb = X_candidates[next_idx]\n",
    "\n",
    "\n",
    "print(f\"Current best observed value: {np.max(f7_outputs):.4f}\")\n",
    "print(\"Inputs producing current best:\", f7_inputs[np.argmax(f7_outputs)])\n",
    "print(\"Next sample point (ucb):\", next_point_ucb)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point_ucb.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a4dc3",
   "metadata": {},
   "source": [
    "Submission for week 4: 0.036332-0.920708-0.509829-0.218803-0.361421-0.824300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b2d36",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 7\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f7_inputs = np.vstack([f7_inputs, row['provided_input'].values[0]])\n",
    "f7_outputs = np.append(f7_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f7_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f7_inputs):.4f}, {np.max(f7_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f7_outputs):.4f}, {np.max(f7_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "f7_inputs_outputs = np.hstack([f7_inputs, f7_outputs.reshape(f7_inputs.shape[0],1)])\n",
    "#print(f4_inputs_outputs)\n",
    "\n",
    "print(f\"Correlation between inputs and with outputs (last column): \\n{np.corrcoef(f7_inputs_outputs, rowvar=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b7428",
   "metadata": {},
   "source": [
    "1st, 5th and 6th dimension are the ones with the highest correlation with the outputs in absolute value.\n",
    "\n",
    "From the given data, \"good\" input values are those that produce an output > 1.3.\n",
    "\n",
    "For the sake of experimentation and application of techniques, I am going to train a SVM classifier on this 6D space to separate the \"good\" part from the \"bad\" part of this 6D hypercube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_with_kernel = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC(kernel=\"poly\", degree=3, C=100, probability=True))\n",
    "])\n",
    "\n",
    "f7_output_types = (f7_outputs >= 1.3).astype(np.int16)\n",
    "\n",
    "svm_with_kernel.fit(f7_inputs, f7_output_types)\n",
    "\n",
    "f7_outputs_preds = svm_with_kernel.predict(f7_inputs)\n",
    "f7_outputs_preds_probs = svm_with_kernel.predict_proba(f7_inputs)[:, 1]\n",
    "\n",
    "print(f7_outputs_preds)\n",
    "print(f7_outputs_preds_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1c97fa",
   "metadata": {},
   "source": [
    "The datasample is very small to evaluate the classifier, but here is the confusion matrix and accuracy score. Is it overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18668a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Confusion matrix: \\n{confusion_matrix(f7_output_types, f7_outputs_preds)}\")\n",
    "print(f\"Accuracy: {accuracy_score(f7_output_types, f7_outputs_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778fd996",
   "metadata": {},
   "source": [
    "Let's explore the 6D-dimensional hypercube and try to find a point with the highest probability of belonging to the \"good\" category while being the furthest away from all known points so far to encourage exploration and test this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 6\n",
    "n_samples = 200_000\n",
    "lambda_distance = 0.5 # to play with to weigh distance importance\n",
    "\n",
    "np.random.seed(42)\n",
    "samples = np.random.rand(n_samples, dims)\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(f7_inputs)\n",
    "distances, _ = neighbors.kneighbors(samples)\n",
    "distances = distances.flatten()\n",
    "\n",
    "f7_outputs_preds_probs = svm_with_kernel.predict_proba(samples)[:, 1]\n",
    "\n",
    "score = f7_outputs_preds_probs.flatten() + lambda_distance * distances\n",
    "\n",
    "best_idx = np.argmax(score)\n",
    "best_point = samples[best_idx]\n",
    "best_prob = f7_outputs_preds_probs[best_idx]\n",
    "best_dist = distances[best_idx]\n",
    "\n",
    "print(f\"Probability of being good input: {best_prob:.4f}\")\n",
    "print(f\"Distance from known points: {best_dist:.4f}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f7_outputs)]}\")\n",
    "print(\"Next point to sample based on distance and prediction:\", best_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in best_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd91559",
   "metadata": {},
   "source": [
    "Input for week 5: 0.020515-0.735827-0.008273-0.047345-0.254657-0.980806"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9b8702",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 7\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f7_inputs = np.vstack([f7_inputs, row['provided_input'].values[0]])\n",
    "f7_outputs = np.append(f7_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f7_outputs):.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")\n",
    "print('--')\n",
    "print(f\"Inputs shape: {f7_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f7_inputs):.4f}, {np.max(f7_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f7_outputs):.4f}, {np.max(f7_outputs):.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f814cd2",
   "metadata": {},
   "source": [
    "## Function 8\n",
    "\n",
    "This function is a function with a 1D output and a 8D input. \n",
    "\n",
    "This is the description of the function: You’re optimising an eight-dimensional black-box function, where each of the eight input parameters affects the output, but the internal mechanics are unknown. \n",
    "\n",
    "Your objective is to find the parameter combination that maximises the function’s output, such as performance, efficiency or validation accuracy. Because the function is high-dimensional and likely complex, global optimisation is hard, so identifying strong local maxima is often a practical strategy.\n",
    "\n",
    "For example, imagine you’re tuning an ML model with eight hyperparameters: learning rate, batch size, number of layers, dropout rate, regularisation strength, activation function (numerically encoded), optimiser type (encoded) and initial weight range. Each input set returns a single validation accuracy score between 0 and 1. Your goal is to maximise this score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190db870",
   "metadata": {},
   "source": [
    "### Week 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations: {len(f8_inputs)}\")\n",
    "print(f\"Inputs shape: {f8_inputs.shape}\")\n",
    "print(f\"Inputs range: [{np.min(f8_inputs):.4f}, {np.max(f8_inputs):.4f}]\")\n",
    "print(f\"Performance range: [{np.min(f8_outputs):.4f}, {np.max(f8_outputs):.4f}]\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's another high-dimensional function with not much information about it. I will replicate the random sampling technique and kernels and acquisition from function 7.\n",
    "\n",
    "kernel = (\n",
    "    C(1.0, (1e-6, 1e6)) * (\n",
    "        RBF([1.0]*8, length_scale_bounds=(1e-2, 1e25)) +\n",
    "        Matern(length_scale=[1.0]*8, length_scale_bounds=(1e-2,1e25), nu=2.5)\n",
    "    ) +\n",
    "    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f8_inputs, f8_outputs)\n",
    "\n",
    "margin = 0.01  # avoid boundaries, previous function gave a 1 for one of the coordinates\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "n_candidates = 1000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 8)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 2.5 \n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7039b88c",
   "metadata": {},
   "source": [
    "Submission for week 1: 0.053588-0.199773-0.065100-0.022307-0.890284-0.392617-0.053845-0.582385\n",
    "\n",
    "It is noted that I am getting many warnings about length scale, which is a topic to address the next week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3bf42",
   "metadata": {},
   "source": [
    "### Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89d6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 8\n",
    "week = 1 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f8_inputs = np.vstack([f8_inputs, row['provided_input'].values[0]])\n",
    "f8_outputs = np.append(f8_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee64bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Correlation between inputs: \\n{np.corrcoef(f8_inputs, rowvar=False)}\\n\")\n",
    "\n",
    "print('Means:', f8_inputs.mean(axis=0))\n",
    "print('Stds:', f8_inputs.std(axis=0))\n",
    "print('Mins:', f8_inputs.min(axis=0))\n",
    "print('Maxs:', f8_inputs.max(axis=0))\n",
    "print('Std/Mean Ratios:', f8_inputs.std(axis=0) / (f8_inputs.mean(axis=0) + 1e-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc985edb",
   "metadata": {},
   "source": [
    "It is encouraged to exploit local minima, which we will start doing considering the improvement through the acquisition function. For the moment I am keeping UCB with a smaller kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73290bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's another high-dimensional function with not much information about it. I will replicate the random sampling technique and kernels and acquisition from function 7.\n",
    "\n",
    "kernel = (\n",
    "    C(1.0, (1e-6, 1e6)) * (\n",
    "        RBF([1.0]*8, length_scale_bounds=(1e-2, 1e2)) +\n",
    "        Matern(length_scale=[1.0]*8, length_scale_bounds=(1e-2,1e2), nu=1.5)\n",
    "    ) +\n",
    "    WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    ")\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f8_inputs, f8_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "margin = 0.01  # avoid boundaries, previous function gave a 1 for one of the coordinates\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "n_candidates = 1000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 8)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 0.25\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f199531",
   "metadata": {},
   "source": [
    "Submission for week 2: 0.076967-0.216041-0.229342-0.023042-0.977037-0.446917-0.188639-0.130387"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af408fcd",
   "metadata": {},
   "source": [
    "### Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 8\n",
    "week = 2 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f8_inputs = np.vstack([f8_inputs, row['provided_input'].values[0]])\n",
    "f8_outputs = np.append(f8_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6337127",
   "metadata": {},
   "source": [
    "This is really a marginal improvement over next week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97ff83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the RBF kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[1.0]*8, length_scale_bounds=(1e-2, 1e3), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    "\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f8_inputs, f8_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "margin = 0.01  # avoid boundaries, previous function gave a 1 for one of the coordinates\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "n_candidates = 1000000  # Much more manageable\n",
    "np.random.seed(42)\n",
    "X_candidates = np.random.uniform(\n",
    "    low=margin, \n",
    "    high=1-margin, \n",
    "    size=(n_candidates, 8)\n",
    ")\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c45aa",
   "metadata": {},
   "source": [
    "Submission for week 3: 0.054303-0.023167-0.046826-0.146788-0.981370-0.541223-0.235202-0.585401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9b272",
   "metadata": {},
   "source": [
    "### Week 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5979c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 8\n",
    "week = 3 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f8_inputs = np.vstack([f8_inputs, row['provided_input'].values[0]])\n",
    "f8_outputs = np.append(f8_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50358c53",
   "metadata": {},
   "source": [
    "Although small, this was an improvement.\n",
    "\n",
    "This week I am using the same technique without the RBF component to the kernel, but replacing the way of evaluating random points of the GP with a Sobol sampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dcb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 8\n",
    "\n",
    "# Dropping the RBF kernel\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=[1.0]*dims, length_scale_bounds=(1e-2, 1e3), nu=2.5) \\\n",
    "         + WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-13, 1e-1))\n",
    "\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=1e-6,\n",
    "                              normalize_y=True,\n",
    "                              n_restarts_optimizer=20,\n",
    "                              random_state=42)\n",
    "gp.fit(f8_inputs, f8_outputs)\n",
    "print(gp.kernel_)\n",
    "\n",
    "margin = 0.01  # avoid boundaries, previous function gave a 1 for one of the coordinates\n",
    "\n",
    "# Random sampling approach to avoid memory issues\n",
    "# n_candidates = 1000000  # Much more manageable\n",
    "\n",
    "np.random.seed(42)\n",
    "#X_candidates = np.random.uniform(\n",
    "#   low=margin, \n",
    "#    high=1-margin, \n",
    "#   size=(n_candidates, 8)\n",
    "#)\n",
    "\n",
    "sampler = qmc.Sobol(d=dims, scramble=True, seed=42)\n",
    "#X_candidates = sampler.random(n_candidates)\n",
    "X_candidates = sampler.random_base2(m=20) # 2**20 samples\n",
    "X_candidates = margin + (1 - 2 * margin) * X_candidates  # stay inside (margin, 1-margin)\n",
    "\n",
    "y_mean, y_std = gp.predict(X_candidates, return_std=True)\n",
    "\n",
    "# UCB acquisition function\n",
    "kappa = 0.5\n",
    "UCB = y_mean + kappa * y_std \n",
    "\n",
    "next_idx = np.argmax(UCB)\n",
    "next_point = X_candidates[next_idx]\n",
    "\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n",
    "print(\"Next point to sample based on UCB:\", next_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in next_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a94c6c",
   "metadata": {},
   "source": [
    "Sample for week 4: 0.229166-0.133413-0.151014-0.018894-0.960755-0.438649-0.170407-0.911107"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f52dd",
   "metadata": {},
   "source": [
    "### Week 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6edddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 8\n",
    "week = 4 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f8_inputs = np.vstack([f8_inputs, row['provided_input'].values[0]])\n",
    "f8_outputs = np.append(f8_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f51e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f8_inputs_outputs = np.hstack([f8_inputs, f8_outputs.reshape(f8_inputs.shape[0],1)])\n",
    "#print(f4_inputs_outputs)\n",
    "\n",
    "print(f\"Correlation between inputs and with outputs (last column): \\n{np.corrcoef(f8_inputs_outputs, rowvar=False)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350dc996",
   "metadata": {},
   "source": [
    "Outputs are most correlated with the first and third input, negatively.\n",
    "\n",
    "Let's see if we can reduce the inputs to 4D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02921ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 4)\n",
    "f8_inputs_3d = pca.fit_transform(f8_inputs)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66632acb",
   "metadata": {},
   "source": [
    "Variance would only be explained up to 0.68.\n",
    "\n",
    "The function description encourages the exploration of local minima, which we seem to have found with an output value > 9.\n",
    "\n",
    "For experimentation purposes I want to train a neural network based on these 8 dimensions to determine whether the inputs produce \"good\" outputs (>8.9). Then I can allow myself to perform a random search accross the 8D space to find other points with good outputs as far as possible from known points. This may allow me to find another area with local minima to explore which may even yield higher outpupt values. Can be fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Sequential model construction\n",
    "model = Sequential([\n",
    "    layers.Dense(8, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "x = tf.convert_to_tensor(f8_inputs.astype(np.float32))\n",
    "y = (f8_outputs >= 8.5)\n",
    "y = tf.convert_to_tensor(y.astype(np.int16))\n",
    "\n",
    "model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"binary_crossentropy\")\n",
    "\n",
    "history = model.fit(x,y, epochs=550, validation_split=0.15)\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "# (Optional) Visualize the computational graph\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "# Display in Jupyter Notebook\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to find the point with the highest probability of having a 1 (good value) acording to the NN that is furthest away from known points.\n",
    "\n",
    "dims = 8\n",
    "n_samples = 100_000\n",
    "lambda_distance = 0.5 # to play with to weigh distance importance\n",
    "\n",
    "np.random.seed(42)\n",
    "samples = np.random.rand(n_samples, dims)\n",
    "\n",
    "probs_of_good_result = model.predict(samples, verbose=0).flatten()\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(f8_inputs)\n",
    "distances, _ = neighbors.kneighbors(samples)\n",
    "distances = distances.flatten()\n",
    "\n",
    "score = probs_of_good_result + lambda_distance * distances\n",
    "\n",
    "best_idx = np.argmax(score)\n",
    "best_point = samples[best_idx]\n",
    "best_prob = probs_of_good_result[best_idx]\n",
    "best_dist = distances[best_idx]\n",
    "\n",
    "print(f\"Probability of being good input: {best_prob:.4f}\")\n",
    "print(f\"Distance from known points: {best_dist:.4f}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Inputs producing current best: {f8_inputs[np.argmax(f8_outputs)]}\")\n",
    "print(\"Next point to sample based on distance and prediction:\", best_point)\n",
    "print(\"-\".join(f\"{x:.6f}\" for x in best_point.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ba91b",
   "metadata": {},
   "source": [
    "Submission for week 5: 0.066684-0.029599-0.012412-0.855233-0.692224-0.676637-0.760723-0.973119\n",
    "\n",
    "*I was unable to fix the random seed for TF this week, so probably next runs will yield different points. However the one listed here is the one submitted as part of this capstone project.\n",
    "\n",
    "Let's see if the NN has learned the underlying patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd60156a",
   "metadata": {},
   "source": [
    "### Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load points to inputs and outputs from previous week\n",
    "function = 8\n",
    "week = 5 #previous\n",
    "\n",
    "row = results_df[(results_df['week'] == week) & (results_df['function'] == function)]\n",
    "f8_inputs = np.vstack([f8_inputs, row['provided_input'].values[0]])\n",
    "f8_outputs = np.append(f8_outputs, row['output'].values[0])\n",
    "\n",
    "improved = row['submission_improved'].values[0]\n",
    "print(f\"Submission from last week improved something? {improved}\")\n",
    "print(f\"Current best: {np.max(f8_outputs):.4f}\")\n",
    "print(f\"Previous best: {results_df[(results_df['week'] == week-1) & (results_df['function'] == function)]['known_best'].values[0]:.4f}\")\n",
    "print(f\"Last week's results: {row['output'].values[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
